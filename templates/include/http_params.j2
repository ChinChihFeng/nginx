## Size Limits
client_body_buffer_size             10M; # This handles the client buffer size, meaning any POST actions sent to Nginx. POST actions are typically form submissions.
client_header_buffer_size           1k; # Similar to the previous directive, only instead it handles the client header size. For all intents and purposes, 1K is usually a decent size for this directive.
client_max_body_size            10240k; # this needs to be increased if you are receiving file uploads via the POST method.
large_client_header_buffers       2 2k; # The maximum number and size of buffers for large client headers.

# Timeouts, do not keep connections open longer then necessary to reduce resource usage and deny Slowloris type attacks.
client_body_timeout                 3s; # maximum time between packets the client can pause when sending nginx any data
client_header_timeout               3s; # maximum time the client has to send the entire header to nginx
keepalive_timeout                   6s; # timeout which a single keep-alive client connection will stay open
send_timeout                        3s; # maximum time between packets nginx is allowed to pause when sending the client data

## General Options
charset                          utf-8; # adds the line "Content-Type" into response-header, same as "source_charset"
default_type 			 application/octet-stream;
gzip                                on; # disable on the fly gzip compression due to higher latency, only use gzip_static
gzip_comp_level                      1; # 1-4 depending on CPU cores
#gzip_http_version                 1.0; # serve gzipped content to all clients including HTTP/1.0
gzip_static                         on;  # precompress content (gzip -1) with an external script
gzip_min_length                   4096; # min file size in bytes
gzip_vary                           on;  # send response header "Vary: Accept-Encoding"
gzip_proxied                       any;  # allows compressed responses for any request even from proxies
gzip_types                          text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript text/x-js;
#gzip_buffers                    16 8k;
gzip_buffers           		 128 32k;
ignore_invalid_headers              on;
include                             mime.types;
keepalive_requests                  100;  # number of requests per connection, does not affect SPDY - set higher for frequent queries
keepalive_disable                   none; # allow all browsers to use keepalive connections
max_ranges                          0;   # disabled to stop range header DoS attacks as resumed downloads are denied
msie_padding                        off;
postpone_output                     1460;   # postpone sends to match our machine's MSS
recursive_error_pages               on;
reset_timedout_connection           on;  # reset timed out connections freeing ram
server_tokens                       off; # version number in error pages
server_name_in_redirect             off; # if off, nginx will use the requested Host header
source_charset                      utf-8; # same value as "charset"
tcp_nodelay                         on; # Nagle buffering algorithm, used for keepalive only
tcp_nopush                          off; # If set to on, do not send out partial frames. Enable if using sendfile

## With ZFS + FreeBSD
#  aio                        on; # asynchronous file input/output, fast with ZFS, make sure sendfile=off
# #directio                  off; # zfs does not support direct i/o because of the ARC and L2ARC
# #open_file_cache          max=128 inactive=4h; # cache is not be needed if ZFS ARC size is sufficient
# #open_file_cache_errors     on;                # since ARC delivery is faster then the cache lookups
# #open_file_cache_min_uses    1;
# #open_file_cache_valid      3h;
#  output_buffers          1 64K; # sendfile=off so set to the total size of all objects on an average page
#  read_ahead                  0; # no forced read ahead, let ZFS handle I/O calls as zfs is efficient
#  sendfile                  off; # off for FreeBSD and ZFS to avoid redundant data caching

## Without ZFS (General Linux)
# directio               512;

open_file_cache           max=2000 inactive=60s;
open_file_cache_errors    on;
open_file_cache_min_uses   2;
open_file_cache_valid     120s;

#  output_buffers          1 64; # Depends on the avg size per page, or larger (512) output buffers for heavy content
read_ahead               64K; # kernel read head set to the output_buffers
sendfile                  off; # off for FreeBSD and ZFS to avoid redundant data caching

more_set_headers    	"Server: NWS";
